<!DOCTYPE html>
<html  >
<head>
  <!-- Site made with Mobirise Website Builder v4.10.5, https://mobirise.com -->
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Mobirise v4.10.5, mobirise.com">
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
  <link rel="shortcut icon" href="assets/images/icons8-news-80-80x80.png" type="image/x-icon">
  <meta name="description" content="Website Builder Description">
  
  <title>Deepfakes</title>
  <link rel="stylesheet" href="assets/web/assets/mobirise-icons/mobirise-icons.css">
  <link rel="stylesheet" href="assets/tether/tether.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap-grid.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap-reboot.min.css">
  <link rel="stylesheet" href="assets/dropdown/css/style.css">
  <link rel="stylesheet" href="assets/theme/css/style.css">
  <link rel="stylesheet" href="assets/mobirise/css/mbr-additional.css" type="text/css">
  
  
  
</head>
<body>
  <section class="menu cid-rw4ZRFWTas" once="menu" id="menu1-x">

    

    <nav class="navbar navbar-expand beta-menu navbar-dropdown align-items-center navbar-fixed-top navbar-toggleable-sm">
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <div class="hamburger">
                <span></span>
                <span></span>
                <span></span>
                <span></span>
            </div>
        </button>
        <div class="menu-logo">
            <div class="navbar-brand">
                
                <span class="navbar-caption-wrap"><a class="navbar-caption text-white display-7" href="index.html">SOMETHING AWESOME</a></span>
            </div>
        </div>
        <div class="collapse navbar-collapse" id="navbarSupportedContent">
            <ul class="navbar-nav nav-dropdown nav-right" data-app-modern-menu="true"><li class="nav-item dropdown open">
                    <a class="nav-link link text-white dropdown-toggle display-7" href="https://mobirise.co" data-toggle="dropdown-submenu" aria-expanded="true"><span class="mbri-sites mbr-iconfont mbr-iconfont-btn"></span>
                        
                        Articles</a><div class="dropdown-menu"><a class="text-white dropdown-item display-7" href="ransomware.html">Ransomware<br></a><a class="text-white dropdown-item display-7" href="piracy.html" aria-expanded="false">Software Piracy</a></div>
                </li>
                <li class="nav-item">
                    <a class="nav-link link text-white display-7" href="https://mobirise.co"><span class="mbri-italic mbr-iconfont mbr-iconfont-btn"></span>
                        
                        About</a>
                </li></ul>
            
        </div>
    </nav>
</section>

<section class="engine"><a href="https://mobirise.info">Mobirise</a></section><section class="mbr-section content5 cid-rw4ZRHaMhO mbr-parallax-background" id="content5-y">

    

    

    <div class="container">
        <div class="media-container-row">
            <div class="title col-12 col-md-8">
                <h2 class="align-center mbr-bold mbr-white pb-3 mbr-fonts-style display-1">
                    DEEPFAKES</h2>
                <h3 class="mbr-section-subtitle align-center mbr-light mbr-white pb-3 mbr-fonts-style display-5">Machine learning, AI and the Threat to Digital Security</h3>
                
                
            </div>
        </div>
    </div>
</section>

<section class="mbr-section article content14 cid-rw4ZRIiAYb" id="content14-z">
      
     

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
                <div class="col-12 mbr-text mbr-fonts-style col-md-12 display-7">
                     <p class="p-3">Deepfakes are fake videos or audio recordings that look and sound just like the real thing. Deepfakes first emerged in 2017, when an anonymous Reddit user posted links to pornographic videos that appeared to feature famous mainstream celebrities. These videos were faked using artificial intelligence tools. From then on, there have been various viral videos featuring edits of a variety of celebrities. With the growing prevalence of this technology comes growing concern around issues of safety and privacy, as well as an ongoing debate about ‘fake news’.</p>
                </div>
                
                
            </div>
        </div>
    </div>
</section>

<section class="cid-rw50qRryc7" id="video3-1a">

    
    
    <figure class="mbr-figure align-center container">
        <div class="video-block" style="width: 58%;">
            <div><iframe class="mbr-embedded-video" src="https://www.youtube.com/embed/cQ54GDm1eL0?rel=0&amp;amp;showinfo=0&amp;autoplay=1&amp;loop=0" width="1280" height="720" frameborder="0" allowfullscreen></iframe></div>
        </div>
    </figure>
</section>

<section class="mbr-section article content14 cid-rw4ZRJ7nbQ" id="content14-10">
      
     

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
                <div class="col-12 mbr-text mbr-fonts-style col-md-12 display-7">
                     <p class="p-3"><strong>How Deepfakes are Made
<br></strong><span style="font-size: 1rem;">The original deepfakes were created using artificial intelligence built on Google’s open-source machine learning library. This deepfake algorithm uses deep learning AI to replace one face with another. More specifically, they use a technology called generative adversarial networks (GANs) which is broadly used to create fake data that can pass as real data. GANs consist of two machine learning algorithms that are pitted against one another. One creates fake data and the other judges the quality of the fake data based on existing real data. These two algorithms work together, constantly improving the resulting data at an immense rate. In the application of deepfakes, the authentic data consists of hundreds or thousands of still images of a person’s face, with a wide selection of angles and differing facial expressions to choose from and to judge against.&nbsp;</span></p>
                </div>
                
                
            </div>
        </div>
    </div>
</section>

<section class="cid-rw4ZRJJtSx" id="image1-11">

    

    <figure class="mbr-figure container">
        <div class="image-block" style="width: 58%;">
            <img src="assets/images/deepfake-learning-1288x746.jpg" width="1400" alt="John Oliver Jimmy Fallon Deep Learning Training" title="Neural Network learning how to generate Jimmy Fallon and John Oliver's faces">
            
        </div>
    </figure>
</section>

<section class="mbr-section article content14 cid-rw52zKEgQo" id="content14-1f">
      
     

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
                <div class="col-12 mbr-text mbr-fonts-style col-md-12 display-7">
                     <p class="p-3"><em>Neural Network learning how to generate Jimmy Fallon and John Oliver's faces</em></p>
                </div>
                
                
            </div>
        </div>
    </div>
</section>

<section class="mbr-section article content14 cid-rw4ZRKgSEL" id="content14-12">
      
     

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
                <div class="col-12 mbr-text mbr-fonts-style col-md-12 display-7">
                     <p class="p-3">These visual effects tricks are not a new technology. We have had realistic computer-generated videos in big-budget Hollywood productions for quite some time, with notable examples in Fast &amp; Furious 7 and Star Wars Rogue One. Using CGI and special effects, big budget studios have been able to recreate faces with quite convincing results. However, with the emergence of deepfakes, it has become a much easier task to accomplish. With a variety of free apps such as FakeApp and DeepFaceLab available online, digital video manipulation has never been more accessible. With this increase in accessibility, the security implications of this technology are enormous.</p>
                </div>
                
                
            </div>
        </div>
    </div>
</section>

<section class="mbr-section article content14 cid-rw4ZRLzK92" id="content14-14">
      
     

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
                <div class="col-12 mbr-text mbr-fonts-style col-md-12 display-7">
                     <p class="p-3"><strong>Fake News and the Imminent Threat to Politics
<br></strong><span style="font-size: 1rem;">Countless deepfake videos have already been circulated around the internet, many of which feature notable political figures such as Donald Trump. Although many of these videos are created for comedic purposes, this technology could easily be used to disgrace politicians and swing elections. Recently, a digitally altered video of Nancy Pelosi, the speaker of the US House of Representatives was shared across Facebook and YouTube. In this clip, she appears to stammer and slur drunkenly through a speech. This doctored footage was eventually shared by Donald Trump on Twitter with the caption “PELOSI STAMMERS THROUGH NEWS CONFERENCE”. Although this video was quickly debunked as fake, it had already amassed millions of views.<br><br>Deepfakes are already affecting the landscape of politics and will without a doubt grow in prominence.</span></p>
                </div>
                
                
            </div>
        </div>
    </div>
</section>

<section class="cid-rw5aXK7JSi" id="video3-1i">

    
    
    <figure class="mbr-figure align-center container">
        <div class="video-block" style="width: 58%;">
            <div><iframe class="mbr-embedded-video" src="https://www.youtube.com/embed/rvF5IA7HNKc?rel=0&amp;amp;showinfo=0&amp;autoplay=1&amp;loop=0" width="1280" height="720" frameborder="0" allowfullscreen></iframe></div>
        </div>
    </figure>
</section>

<section class="mbr-section article content14 cid-rw5cfDIrMP" id="content14-1j">
      
     

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
                <div class="col-12 mbr-text mbr-fonts-style col-md-12 display-7">
                     <p class="p-3"><em>Deepfake of a sketch from The Tonight Show created by YouTube channel 'derpfakes'</em></p>
                </div>
                
                
            </div>
        </div>
    </div>
</section>

<section class="mbr-section article content14 cid-rw4ZROaCW4" id="content14-18">
      
     

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
                <div class="col-12 mbr-text mbr-fonts-style col-md-12 display-7">
                     <p class="p-3"><strong>The Greater Threat to Personal Security
<br></strong><span style="font-size: 1rem;">Beyond the realms of government collusion and internet satire, the technology of deepfakes has greater implications to society. Today’s security systems rely heavily on surveillance video and image based biometric security. Other deepfake-based attacks that are likely to occur include fraud, blackmail or extortion, and with a majority of security breaches occurring from social engineering, there is no doubt this technology will be utilised by criminals in this sector. &nbsp;&nbsp;<br></span><span style="font-size: 1rem;"><br>With this potential for criminal activity, comes another concern for personal privacy. The widespread application of deepfakes for pornography has raised a variety of moral questions. Does a naked image of Person A become a naked image of Person B if Person B’s face is superimposed in a seamless and untraceable way? Recent advancements in deep learning have further tested this sentiment, bringing forth a new wave of nonconsensual porn on the internet.&nbsp;<br></span><span style="font-size: 1rem;"><br>Last month, a programmer created an application that uses neural network sot remove clothing from the images of women. Operating much like deepfakes, the software, called DeepNude superimposes body parts onto an image of a clothed person. This new software builds on the foundations of deepfakes, making it easier to create convincing nude images. The potential for applications in revenge porn and blackmail is unprecedented, with some arguing an invasion of sexual privacy and a claim of ownership over women’s bodies. The problematic nature of the software, as well as the widespread controversy led to the shutdown of the site and app.&nbsp;</span></p>
                </div>
                
                
            </div>
        </div>
    </div>
</section>

<section class="mbr-section article content14 cid-rw5ajWkBPg" id="content14-1g">
      
     

    <div class="container">
        <div class="media-container-row">
            <div class="row col-12 col-md-8">
                <div class="col-12 mbr-text mbr-fonts-style col-md-12 display-7">
                     <p class="p-3"><strong>Fighting the Fake News
<br></strong><span style="font-size: 1rem;">The impacts of deepfakes can already be seen on a large scale across social media. As the technology improves, deepfakes will have enormous implications for fake news, propaganda, evidence tampering and blackmail. Many specialists in the technology are already working to combat this imminent threat.&nbsp;<br></span><span style="font-size: 1rem;"><br>Researchers from the State University of New York have developed a deepfake detection method that uses AI technology to look for natural blinking, breathing and even a pulse. This method is very limited, with it only being a matter of time before deepfakes improve on these characteristics.&nbsp;<br></span><span style="font-size: 1rem;"><br>On a political level, governments have already begun taking precautions. In the US state of Virginia, a bill has already been passed to make amendments to existing laws around revenge porn. This amendment makes explicit concessions for falsely created material. This move is also currently being considered by the US government. &nbsp;<br></span><span style="font-size: 1rem;"><br>Alongside these responses, private companies have begun work on new methods of video authentication. A new cryptographic authentication tool called Amber Authenticate can be run while recording video to generate a hash of the data at specific internals. Any tampering of the video will produce a different hash, alerting the viewer of tampering. This system has been proposed for police body cams and surveillance video.&nbsp;<br></span><span style="font-size: 1rem;"><br>With the growing threat of deepfakes comes a greater need for security. When deepfakes inevitably get really good, only machines will be able to tell the difference between real and fake. In the same way we have come to accept that images can be faked, we will have to adapt this same uncertainty to videos.&nbsp;</span></p>
                </div>
                
                
            </div>
        </div>
    </div>
</section>


  <script src="assets/web/assets/jquery/jquery.min.js"></script>
  <script src="assets/popper/popper.min.js"></script>
  <script src="assets/tether/tether.min.js"></script>
  <script src="assets/bootstrap/js/bootstrap.min.js"></script>
  <script src="assets/smoothscroll/smooth-scroll.js"></script>
  <script src="assets/dropdown/js/nav-dropdown.js"></script>
  <script src="assets/dropdown/js/navbar-dropdown.js"></script>
  <script src="assets/touchswipe/jquery.touch-swipe.min.js"></script>
  <script src="assets/parallax/jarallax.min.js"></script>
  <script src="assets/theme/js/script.js"></script>
  
  
</body>
</html>